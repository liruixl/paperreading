这节看得我有点晕。。

# 给表加个字段怎么有这么多阻碍？

数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。 

根据加锁的范围分类：

+ 全局锁
+ 表锁
+ 行锁

## 全局锁

顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 

**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都 select 出来存成文本。 

让整库只读，缺点：

+ 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
+ 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。

但不加锁的话，系统备份得到的库不是一个逻辑时间点。

其他方法：官方自带的逻辑备份工具是 mysqldump。当 mysqldump **使用参数–single-transaction** 的时候，导数据之前就会启动一个事务，来确保拿到**一致性视图**。而由于 MVCC（Multi-Version Concurrency Control，多版本并发控制 ） 的支持，这个过程中数据是可以正常更新的。 

疑惑：有了这个功能，为什么还需要 FTWRL 呢？**一致性读是好，但前提是引擎要支持这个隔离级别。**比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。 

问题：**既然要全库只读，为什么不使用 set global readonly=true 的方式呢**？ 确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：

+ 一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。
+ 二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。

## 表级锁

业务的更新不只是增删改数据（**DML**，Data Manipulation Language)，还有可能是加字段等修改表结构的操作（**DDL**，**数据定义语言** ）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。 

MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。 

**表锁的语法是 lock tables … read/write。**与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。 当然，也不能跟访问其他表。

**另一类表级的锁是 MDL（metadata lock)。**MDL 不需要显式使用，在访问一个表的时候会被自动加上。 一个查询正在遍历数据，执行期间另一个线程对这个表做了更改，**删了一列**，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。

因此，在 MySQL 5.5 版本中引入了 MDL，MDL作用是防止DDL和DML并发的冲突：

+ 当对一个表做增删改查操作的时候，加 MDL 读锁；这里有疑问，增删改查都是加MDL读锁🔒❗❓
+ 当要对表做结构变更操作的时候，加 MDL 写锁。 

### 如何安全地给小表加字段？

如果sessionA对表加MDL读锁，`begin; select * ...;`。此时由于sessionC要加字段，需要MDL写锁，只能被阻塞。如果只有session C被阻塞没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞 ，等于这个表现在完全不可读写了。 如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。 整个库会挂掉。事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。 

疑问🔒：session C既然阻塞，那就别拿MDL写锁。。可能跟设计有关。或者得有先来后到。

既然session C blocked，拿不到写锁，那么session D为什么会被blocked呢？ 

> 作者回复: 如果说设计初衷，是为了防饿死吧 

解决方案：

+ 首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。 在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。 

+ 对于数据量不大，但请求频繁的表，这时候 kill 可能未必管用，因为新的请求马上就来了。 比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。 
  MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。 

  ```mysql
  ALTER TABLE tbl_name NOWAIT add column ...
  ALTER TABLE tbl_name WAIT N add column ... 
  ```

## 小结

1. 全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，我建议你选择使用–single-transaction 参数，对应用会更友好。 
2. 表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是： 
   + 要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；
   + 要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。
3. MDL 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新，安全第一。

# 问题

## 课后题

备份一般都会在备库上执行，你在用–single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？ 

假设这个 DDL 是针对表 t1 的， 这里我把备份过程中几个关键的语句列出来： 

```mysql
Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；
/* other tables */
Q3:SAVEPOINT sp;
/* 时刻 1 */
Q4:show create table `t1`;
/* 时刻 2 */
Q5:SELECT * FROM `t1`;
/* 时刻 3 */
Q6:ROLLBACK TO SAVEPOINT sp;
/* 时刻 4 */
/* other tables */
```

Q1：在备份开始的时候，为了确保 RR（可重复读）隔离级别，再设置一次 RR 隔离级别 
Q2：启动事务，这里用 WITH CONSISTENT SNAPSHOT 确保这个语句执行完就可以得到一个一致性视图 
Q3：设置一个保存点，这个很重要 
Q4：show create 是为了拿到表结构
Q5：然后正式导数据 
Q6：回滚到 SAVEPOINT sp，在这里的作用是释放 t1 的 MDL 锁

DDL 从主库传过来的时间按照效果不同，我打了四个时刻。题目设定为小表，我们假定到达后，如果开始执行，则很快能够执行完成。 

> 参考答案如下：
>
> 1. 如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。
> 2. 如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump 终止；
> 3. 如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。
> 4. 从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 前的表结构。

## order by问题

老师 我想咨询一个问题 ，我有一个大表t 几百万条数据，a是主键(int类型)，另外有一个索引（b,c,d），查询语句 select a from t where b=‘ZC1093’ and c=‘2018-07-31’ and d=‘AG011’ limit 1000,10 执行过程使用了索引只用了0.014s,查询语句 select a from t where b=‘ZC1093’ and c=‘2018-07-31’ and d=‘AG011’ order by a limit 1000,10 执行过程也用了(b,c,d)这个索引 却用了34s 完成，两条查询语句结果也都是一样的 

> 作者回复: 在《”order by 是怎么工作的”》 这篇会提到这个问题哈 

# 行锁：怎么减少行锁对性能的影响？

MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。 

##  从两阶段锁说起

我先给你举个例子。在下面的操作序列中，事务 B 的 update 语句执行时会是什么现象呢？假设字段 id 是表 t 的主键。 

![1590722653047](assets/1590722653047.png)

与预期一样，实际上事务 B 的 update 语句会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能继续执行。 事务 A 持有的两个记录的行锁，都是在 commit 的时候才释放的。 

**在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。** （需要时加上，也就是执行SQL的时候？释放只能等到事务结束。。）

知道了这个设定，对我们使用事务有什么帮助呢？那就是，**如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。** 

但死锁依然是不可避免的。

## 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。 

当出现死锁以后，有两种策略：

+ 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
+ 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

两种策略各有优缺点：

在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s ，对于在线服务来说，这个等待时间往往是无法接受的。 但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。 

所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。 

新来的线程检查是否死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。 虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。 

## 热点行更新问题

根据上面的分析，我们来讨论一下，**怎么解决由这种热点行更新导致的性能问题呢？**问题的症结在于，死锁检测要耗费大量的 CPU 资源。 

+ **一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。** 风险大，可能出现大量的超时，这是业务有损的。
+ **另一个思路是控制并发度。** 比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。这个并发控制要做在数据库服务端（客户端再少，但会有多个客户端）。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。 
+ 你可以考虑通过将一行改成**逻辑上的多行**来减少锁冲突。 比如，影院账户总额分为10行，每次随机选取其中一条记录来加减。但这类方案需要根据业务逻辑做详细设计，比如边界处理。 

# 问题

最后，我给你留下一个问题吧。如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：

+ 第一种，直接执行 delete from T limit 10000;
+ 第二种，在一个连接中循环执行 20 次 delete from T limit 500;
+ 第三种，在 20 个连接中同时执行 delete from T limit 500。

你会选择哪一种方法呢？为什么呢？

我选第二种，避免了长业务，也减少了连接次数，节省session。

> 第一种方式（即：直接执行 delete from T limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。
>
> 第三种方式（即：在 20 个连接中同时执行 delete from T limit 500），会人为造成锁冲突。

## 检测死锁问题

老师，关于死锁检测innodb_deadlock_detect我想请教一下，是每条事务执行前都会进行检测吗？如果是这样，即使简单的更新单个表的语句，当每秒的并发量达到上千的话，岂不是也会消耗大量资源用于死锁检测吗 

> 作者回复: 是个好问题 如果他要加锁访问的行上有锁，他才要检测。  这里面我担心你有两个误解，说明下： 1. 一致性读不会加锁，就不需要做死锁检测；  2. 并不是每次死锁检测都都要扫所有事务。比如某个时刻，事务等待状态是这样的：     B在等A，    D在等C，    现在来了一个E，发现E需要等D，那么E就判断跟D、C是否会形成死锁，这个检测不用管B和A 



老师，本节课讲的不支持行锁的引擎，只能使用表锁，而表锁同一张表在同一时刻只能有一个更新。但是上节课讲的表级锁中的MDL锁，dml语句会产生MDL读锁，而MDL读锁不是互斥的，也就是说一张表可以同时有多个dml语句操作。感觉这两种说法有点矛盾，请老师解惑！ 

> 作者回复: 不矛盾，MDL锁和表锁是两个不同的结构。 
>
>  比如： 你要在myisam 表上更新一行，那么会加MDL读锁和表的写锁； 然后同时另外一个线程要更新这个表上另外一行，也要加MDL读锁和表写锁。  
>
> 第二个线程的**MDL读锁是能成功加上**的，但是被表写锁堵住了。从语句现象上看，就是第二个线程要等第一个线程执行完成。 

老师：上一节讲的dml时会产生读MDL锁（表锁），也就是update会持有读MDL。读和读不互斥。但是对于行锁来说。两个update同时更新一条数据是互斥的。这个是因为多种锁同时存在时，以粒度最小的锁为准的原因么？ 

> 作者回复: 不是“以粒度最小为准” 而是如果有多种锁，必须得“全部不互斥”才能并行，只要有一个互斥，就得等。  好问题 

